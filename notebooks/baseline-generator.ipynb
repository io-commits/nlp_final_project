{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:33.712642Z",
     "iopub.status.busy": "2022-07-24T12:30:33.711640Z",
     "iopub.status.idle": "2022-07-24T12:30:39.389668Z",
     "shell.execute_reply": "2022-07-24T12:30:39.388581Z",
     "shell.execute_reply.started": "2022-07-24T12:30:33.712198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.398085Z",
     "iopub.status.busy": "2022-07-24T12:30:39.394937Z",
     "iopub.status.idle": "2022-07-24T12:30:39.414102Z",
     "shell.execute_reply": "2022-07-24T12:30:39.411780Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.398045Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_pad(cleaned_df):\n",
    "    tokenizer = Tokenizer()\n",
    "    corpus = cleaned_df.loc[:,'text']\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    # create input sequences using list of tokens\n",
    "    input_sequences = []\n",
    "    \n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    \n",
    "    # pad sequences \n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    # create predictors and label\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    \n",
    "    return predictors, label, tokenizer, input_sequences, max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.416996Z",
     "iopub.status.busy": "2022-07-24T12:30:39.416614Z",
     "iopub.status.idle": "2022-07-24T12:30:39.432879Z",
     "shell.execute_reply": "2022-07-24T12:30:39.431481Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.416960Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_and_compile_model(tokenizer, input_sequences):\n",
    "    total_words= len(tokenizer.word_index) + 1\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "    model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.435887Z",
     "iopub.status.busy": "2022-07-24T12:30:39.435519Z",
     "iopub.status.idle": "2022-07-24T12:30:39.447760Z",
     "shell.execute_reply": "2022-07-24T12:30:39.446544Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.435849Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.title('Training accuracy')\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.453105Z",
     "iopub.status.busy": "2022-07-24T12:30:39.451571Z",
     "iopub.status.idle": "2022-07-24T12:30:39.465191Z",
     "shell.execute_reply": "2022-07-24T12:30:39.464121Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.453067Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_text(model, tokenizer, max_sequence_len, seed_text=\"\", next_words=20):    \n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted=np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.470256Z",
     "iopub.status.busy": "2022-07-24T12:30:39.469746Z",
     "iopub.status.idle": "2022-07-24T12:30:39.478439Z",
     "shell.execute_reply": "2022-07-24T12:30:39.477380Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.470219Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model_name,model):\n",
    "    model.save(f'{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.483502Z",
     "iopub.status.busy": "2022-07-24T12:30:39.483072Z",
     "iopub.status.idle": "2022-07-24T12:30:39.491510Z",
     "shell.execute_reply": "2022-07-24T12:30:39.490299Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.483467Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer_name, tokenizer):\n",
    "    import pickle\n",
    "    with open(f'{tokenizer_name}_tokenizer.pkl', 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.494205Z",
     "iopub.status.busy": "2022-07-24T12:30:39.493850Z",
     "iopub.status.idle": "2022-07-24T12:30:39.560784Z",
     "shell.execute_reply": "2022-07-24T12:30:39.559704Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.494170Z"
    }
   },
   "outputs": [],
   "source": [
    "#kaggle\n",
    "top10k = pd.read_csv('../input/nlp-final-project/pre_processed_top10k.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')\n",
    "top50k = pd.read_csv('../input/nlp-final-project/pre_processed_top50k.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')\n",
    "top100k = pd.read_csv('../input/nlp-final-project/pre_processed_top100k.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')\n",
    "top1m = pd.read_csv('../input/nlp-final-project/pre_processed_top1m.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')\n",
    "\n",
    "# Resource heavy and breaks the cloud\n",
    "# top5m = pd.read_csv('../input/nlp-final-project/pre_processed_top5m.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')\n",
    "\n",
    "# Resource heavy and breaks the cloud\n",
    "# top10m = pd.read_csv('../input/nlp-final-project/pre_processed_top10m.csv', low_memory=False, lineterminator='\\n', index_col=0).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.565960Z",
     "iopub.status.busy": "2022-07-24T12:30:39.565587Z",
     "iopub.status.idle": "2022-07-24T12:30:39.575479Z",
     "shell.execute_reply": "2022-07-24T12:30:39.574185Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.565924Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = list([\n",
    "    ('top10k', top10k),\n",
    "    ('top50k', top50k),\n",
    "    ('top100k', top100k),\n",
    "    ('top1m', top1m)\n",
    "    # ('top5m', top5m) breaks the cloud\n",
    "    # ('top10m', top10m) breaks the cloud\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.583581Z",
     "iopub.status.busy": "2022-07-24T12:30:39.583223Z",
     "iopub.status.idle": "2022-07-24T12:30:39.605417Z",
     "shell.execute_reply": "2022-07-24T12:30:39.604566Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.583547Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs[0][1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:30:39.609272Z",
     "iopub.status.busy": "2022-07-24T12:30:39.608405Z",
     "iopub.status.idle": "2022-07-24T13:55:32.491114Z",
     "shell.execute_reply": "2022-07-24T13:55:32.489632Z",
     "shell.execute_reply.started": "2022-07-24T12:30:39.609238Z"
    }
   },
   "outputs": [],
   "source": [
    "max_seq_list = list()\n",
    "for df in tqdm(dfs):\n",
    "    predictors, labels, tokenizer, input_sequences, max_sequence_len = tokenize_and_pad(df[1])\n",
    "    model = create_and_compile_model(tokenizer, input_sequences)\n",
    "    history = model.fit(predictors, labels, epochs=300, verbose=0)\n",
    "    plot(history)\n",
    "    save_model(df[0], model)\n",
    "    save_tokenizer(df[0], tokenizer)\n",
    "    max_seq_list.append(max_sequence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:55:32.493513Z",
     "iopub.status.busy": "2022-07-24T13:55:32.492569Z",
     "iopub.status.idle": "2022-07-24T13:56:02.082376Z",
     "shell.execute_reply": "2022-07-24T13:56:02.081420Z",
     "shell.execute_reply.started": "2022-07-24T13:55:32.493474Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loadedtop10k = tf.keras.models.load_model('./top10k')\n",
    "loadedtop50k = tf.keras.models.load_model('./top50k')\n",
    "loadedtop100k = tf.keras.models.load_model('./top100k')\n",
    "loadedtop1m = tf.keras.models.load_model('./top1m')\n",
    "# loadedtop5m = tf.keras.models.load_model('./top5m') breaks the cloud\n",
    "# loadedtop10m = tf.keras.models.load_model('./top10m') breaks the cloud\n",
    "models=[loadedtop10k, loadedtop50k, loadedtop100k, loadedtop1m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T14:19:51.481557Z",
     "iopub.status.busy": "2022-07-24T14:19:51.481216Z",
     "iopub.status.idle": "2022-07-24T14:19:51.486628Z",
     "shell.execute_reply": "2022-07-24T14:19:51.485613Z",
     "shell.execute_reply.started": "2022-07-24T14:19:51.481529Z"
    }
   },
   "outputs": [],
   "source": [
    "seed_text = \"no to war yes to peace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T14:19:53.433331Z",
     "iopub.status.busy": "2022-07-24T14:19:53.432981Z",
     "iopub.status.idle": "2022-07-24T14:19:56.678741Z",
     "shell.execute_reply": "2022-07-24T14:19:56.677794Z",
     "shell.execute_reply.started": "2022-07-24T14:19:53.433302Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "for (name,_), model, max_seq in zip(dfs, models, max_seq_list):\n",
    "    with open(f'{name}_tokenizer.pkl', 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "        predicted_text = predict_text(model, tokenizer, max_seq, next_words=20, seed_text=seed_text)\n",
    "        print(f'{name}\\n{predicted_text}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:56:20.947855Z",
     "iopub.status.busy": "2022-07-24T13:56:20.947502Z",
     "iopub.status.idle": "2022-07-24T13:56:20.954511Z",
     "shell.execute_reply": "2022-07-24T13:56:20.953531Z",
     "shell.execute_reply.started": "2022-07-24T13:56:20.947821Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "names=list()\n",
    "for df in dfs: \n",
    "    names.append(df[0])\n",
    "with open('seq_dict.json', 'w') as f:\n",
    "    json.dump({k: v for k, v in zip(names, max_seq_list)}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:56:20.956488Z",
     "iopub.status.busy": "2022-07-24T13:56:20.955909Z",
     "iopub.status.idle": "2022-07-24T13:56:20.970127Z",
     "shell.execute_reply": "2022-07-24T13:56:20.968896Z",
     "shell.execute_reply.started": "2022-07-24T13:56:20.956452Z"
    }
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:56:20.972568Z",
     "iopub.status.busy": "2022-07-24T13:56:20.971477Z",
     "iopub.status.idle": "2022-07-24T13:56:29.587450Z",
     "shell.execute_reply": "2022-07-24T13:56:29.586332Z",
     "shell.execute_reply.started": "2022-07-24T13:56:20.972531Z"
    }
   },
   "outputs": [],
   "source": [
    "! zip -r outputs.zip ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
